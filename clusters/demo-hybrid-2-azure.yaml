kind: Cluster
metadata:
  name: demo-hybrid-2-azure
  space: default
spec:
  kublrAgentTgzUrl: 'https://repo.kublr.com/repository/gobinaries/kublr/1.20.9-18/kublr-1.20.9-18-linux.tar.gz'
  locations:
    - name: azure1
      azure:
        azureApiAccessSecretRef: azure
        region: eastus
        virtualNetworkSubnetCidrBlock: 172.18.0.0/16
        armTemplateExtras:
          securityGroup:
            properties:
              securityRules:
                - name: submariner
                  properties:
                    description: Allow UDP traffic for submariner IPSec VPN
                    protocol: Udp
                    sourcePortRange: '*'
                    sourceAddressPrefix: '*'
                    destinationPortRanges: [500, 4490, 4500]
                    destinationApplicationSecurityGroups:
                      - id: "[resourceId('Microsoft.Network/applicationSecurityGroups', variables('k8sMasterApplicationSecurityGroup'))]"
                    access: Allow
                    priority: 200
                    direction: Inbound
  network:
    clusterCIDR: 100.128.0.0/10
    dnsDomain: cluster2.local
    apiServerSecurePort: 6443
    enableLocalDns: false
    provider: cni-flannel
    stubDomains:
      - dns: cluster1.local
        servers:
          - 100.64.0.10
  master:
    minNodes: 1
    kublrAgentConfig:
      kublr:
        psp:
          default_clusterrole: 'psp:privileged'
    locations:
      - locationRef: azure1
        azure:
          groupType: VirtualMachineScaleSet
          zones:
            - '1'
          pinToZone: pin
          sshKeySecretRef: ssh-pub
          instanceType: Standard_D4s_v4
          osDisk:
            type: image
            imagePublisher: Canonical
            imageOffer: 0001-com-ubuntu-server-focal
            imageVersion: 20_04-lts
            diskSizeGb: 40
          masterDataDisk:
            lun: 1
            diskSizeGb: 15
          masterLBAllocationPolicy: privateAndPublic
          masterLBSeparate: false
          armTemplateExtras:
            scaleSet:
              apiVersion: '2021-07-01'
              properties:
                singlePlacementGroup: false
                virtualMachineProfile:
                  priority: Spot
                  evictionPolicy: Delete
                  billingProfile:
                    maxPrice: -1
                spotRestorePolicy:
                  enabled: true
                  restoreTimeout: P2D
  nodes:
    - name: group1
      minNodes: 3
      stateful: true
      kublrAgentConfig:
        labels:
          submariner.io/gateway: 'true'
      locations:
        - locationRef: azure1
          azure:
            groupType: VirtualMachineScaleSet
            zones:
              - '1'
              - '2'
              - '3'
            pinToZone: pin
            sshKeySecretRef: ssh-pub
            instanceType: Standard_D4s_v4
            osDisk:
              type: image
              imagePublisher: Canonical
              imageOffer: 0001-com-ubuntu-server-focal
              imageVersion: 20_04-lts
              diskSizeGb: 40
            armTemplateExtras:
              ipConfiguration:
                properties:
                  publicIPAddressConfiguration:
                    name: pubIP
                    properties:
                      idleTimeoutInMinutes: 15
              scaleSet:
                apiVersion: '2021-07-01'
                properties:
                  singlePlacementGroup: false
                  virtualMachineProfile:
                    priority: Spot
                    evictionPolicy: Delete
                    billingProfile:
                      maxPrice: -1
                  spotRestorePolicy:
                    enabled: true
                    restoreTimeout: P2D
  features:
    kublrOperator:
      chart:
        version: 1.21.2-32
      enabled: true
    system:
      chart:
        version: 1.21.2-30
    logging:
      chart:
        version: 1.21.2-37
      logCollection:
        enabled: false
      sinks:
        - selfHosted:
            enabled: false
            masterNodes: 1
            dataNodes: 1
            clientNodes: 1
        - centralLogging:
            enabled: true
            persistent: true
            size: 128G
            masterNodes: 1
            dataNodes: 1
            clientNodes: 1
            logstashReplicas: 1
    monitoring:
      chart:
        version: 1.21.2-28
      enabled: true
      platformClient:
        enabled: true
        prometheus:
          persistent: false
    ingress:
      chart:
        version: 1.21.2-24
      ingressControllers:
        - nginx:
            enabled: true
            acme:
              enabled: false
    kubedb:
      chart:
        version: 1.21.2-25
      enabled: false
  packages:
    submariner-broker:
      helmVersion: '3.4.0'
      namespace: submariner-k8s-broker
      releaseName: submariner-k8s-broker
      chart:
        name: submariner-k8s-broker
        url: https://submariner-io.github.io/submariner-charts/charts/submariner-k8s-broker-0.11.0.tgz
      values:
        submariner:
          serviceDiscovery: false
    rook-ceph-additional-configuration:
      helmVersion: '3.4.0'
      namespace: kube-system
      releaseName: rook-ceph-additional-configuration
      chart:
        name: raw
        url: https://github.com/itscontained/charts/releases/download/raw-v0.2.5/raw-v0.2.5.tgz
      values:
        resources:
          -
            apiVersion: batch/v1
            kind: Job
            metadata:
              name: rook-ceph-additional-configuration
            spec:
              template:
                spec:
                  serviceAccountName: tiller
                  restartPolicy: OnFailure
                  containers:
                    - name: import-crd
                      image: cr.kublr.com/bitnami/kubectl:1.21.5
                      command:
                        - sh
                        - -c
                        - |
                          while ! kubectl get crd cephclusters.ceph.rook.io ; do echo waiting for ceph to install ; sleep 5 ; done
                          kubectl apply \
                            -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml \
                            -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml \
                            -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml \
                            -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/rbac-snapshot-controller.yaml \
                            -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/master/deploy/kubernetes/snapshot-controller/setup-snapshot-controller.yaml \
                            -f https://raw.githubusercontent.com/csi-addons/volume-replication-operator/v0.1.0/config/crd/bases/replication.storage.openshift.io_volumereplications.yaml \
                            -f https://raw.githubusercontent.com/csi-addons/volume-replication-operator/v0.1.0/config/crd/bases/replication.storage.openshift.io_volumereplicationclasses.yaml && (
                          kubectl apply -f - <<EOF
                          apiVersion: ceph.rook.io/v1
                          kind: CephRBDMirror
                          metadata:
                            name: my-rbd-mirror
                            namespace: rook-ceph
                          spec:
                            count: 2
                          EOF
                          )
              backoffLimit: 100
          -
            apiVersion: batch/v1beta1
            kind: CronJob
            metadata:
              name: submariner-label-nodes
            spec:
              schedule: "*/1 * * * *"
              successfulJobsHistoryLimit: 1
              jobTemplate:
                spec:
                  template:
                    spec:
                      serviceAccountName: tiller
                      restartPolicy: OnFailure
                      containers:
                        - name: label-nodes
                          image: cr.kublr.com/bitnami/kubectl:1.21.5
                          command:
                            - sh
                            - -c
                            - |
                              kubectl label nodes -l kublr.io/node-group=group1 --overwrite submariner.io/gateway=true
                              for n in $(kubectl get nodes -l kublr.io/node-group=group1 -o name) ; do
                                echo $n gateway.submariner.io/public-ip=ipv4:$(kubectl get $n -o jsonpath='{.status.addresses[?(@.type=="ExternalIP")].address}')
                                kubectl annotate --overwrite $n gateway.submariner.io/public-ip=ipv4:$(kubectl get $n -o jsonpath='{.status.addresses[?(@.type=="ExternalIP")].address}')
                              done
    rook-ceph:
      helmVersion: '3.4.0'
      namespace: rook-ceph
      releaseName: rook-ceph
      chart:
        name: rook-ceph
        url: https://charts.rook.io/release/rook-ceph-v1.7.6.tgz
      values:
        csi:
          enableOMAPGenerator: true
          volumeReplication:
            enabled: true
    rook-ceph-cluster:
      helmVersion: '3.4.0'
      namespace: rook-ceph
      releaseName: rook-ceph-cluster
      chart:
        name: rook-ceph-cluster
        url: https://charts.rook.io/release/rook-ceph-cluster-v1.7.6.tgz
      values:
        # configOverride: {}
        toolbox:
          enabled: true
        # monitoring:
        #  enabled: true
        cephClusterSpec:
          cephVersion:
            image: quay.io/ceph/ceph:v16.2.6
          dataDirHostPath: /var/lib/rook
          dashboard:
            urlPrefix: /ceph-dashboard
          mon:
            count: 3
            volumeClaimTemplate:
              spec:
                storageClassName: kublr-system
                resources:
                  requests:
                    storage: 10Gi
          storage:
            useAllNodes: false
            onlyApplyOSDPlacement: true
            storageClassDeviceSets:
            - name: set1
              count: 3
              placement:
                podAntiAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                  - labelSelector:
                      matchLabels:
                        ceph.rook.io/DeviceSet: set1
                    topologyKey: topology.kubernetes.io/zone
              portable: true
              encrypted: false
              volumeClaimTemplates:
              - metadata:
                  name: data
                spec:
                  resources:
                    requests:
                      storage: 100Gi
                  storageClassName: kublr-system
                  volumeMode: Block
                  accessModes:
                    - ReadWriteOnce
          placement:
            mon:
              podAntiAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchLabels:
                      ceph_daemon_type: mon
                  topologyKey: topology.kubernetes.io/zone
        ingress:
          dashboard:
            host:
              path: /ceph-dashboard
